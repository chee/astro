diff --git a/dist/chunk-HN33TXZT.js b/dist/chunk-HN33TXZT.js
index fbfa5be028ae5f6d03b7dae2b369238cda3df97d..3351a7bd93c6531d53e5adeb88646eb1cf47cc4c 100644
--- a/dist/chunk-HN33TXZT.js
+++ b/dist/chunk-HN33TXZT.js
@@ -1,370 +1,378 @@
 // src/environment.ts
-import { base64Decode, base64Encode } from "@netlify/runtime-utils";
+import { base64Decode, base64Encode } from '@netlify/runtime-utils';
 var getEnvironment = () => {
-  const { Deno, Netlify, process: process2 } = globalThis;
-  return Netlify?.env ?? Deno?.env ?? {
-    delete: (key) => delete process2?.env[key],
-    get: (key) => process2?.env[key],
-    has: (key) => Boolean(process2?.env[key]),
-    set: (key, value) => {
-      if (process2?.env) {
-        process2.env[key] = value;
-      }
-    },
-    toObject: () => process2?.env ?? {}
-  };
+	const { Deno, Netlify, process: process2 } = globalThis;
+	return (
+		Netlify?.env ??
+		Deno?.env ?? {
+			delete: (key) => delete process2?.env[key],
+			get: (key) => process2?.env[key],
+			has: (key) => Boolean(process2?.env[key]),
+			set: (key, value) => {
+				if (process2?.env) {
+					process2.env[key] = value;
+				}
+			},
+			toObject: () => process2?.env ?? {},
+		}
+	);
 };
 var getEnvironmentContext = () => {
-  const context = globalThis.netlifyBlobsContext || getEnvironment().get("NETLIFY_BLOBS_CONTEXT");
-  if (typeof context !== "string" || !context) {
-    return {};
-  }
-  const data = base64Decode(context);
-  try {
-    return JSON.parse(data);
-  } catch {
-  }
-  return {};
+	const context = globalThis.netlifyBlobsContext || getEnvironment().get('NETLIFY_BLOBS_CONTEXT');
+	if (typeof context !== 'string' || !context) {
+		return {};
+	}
+	const data = base64Decode(context);
+	try {
+		return JSON.parse(data);
+	} catch {}
+	return {};
 };
 var setEnvironmentContext = (context) => {
-  const encodedContext = base64Encode(JSON.stringify(context));
-  getEnvironment().set("NETLIFY_BLOBS_CONTEXT", encodedContext);
+	const encodedContext = base64Encode(JSON.stringify(context));
+	getEnvironment().set('NETLIFY_BLOBS_CONTEXT', encodedContext);
 };
 var MissingBlobsEnvironmentError = class extends Error {
-  constructor(requiredProperties) {
-    super(
-      `The environment has not been configured to use Netlify Blobs. To use it manually, supply the following properties when creating a store: ${requiredProperties.join(
-        ", "
-      )}`
-    );
-    this.name = "MissingBlobsEnvironmentError";
-  }
+	constructor(requiredProperties) {
+		super(
+			`The environment has not been configured to use Netlify Blobs. To use it manually, supply the following properties when creating a store: ${requiredProperties.join(
+				', ',
+			)}`,
+		);
+		this.name = 'MissingBlobsEnvironmentError';
+	}
 };
 
 // src/metadata.ts
-import { base64Decode as base64Decode2, base64Encode as base64Encode2 } from "@netlify/runtime-utils";
-var BASE64_PREFIX = "b64;";
-var METADATA_HEADER_INTERNAL = "x-amz-meta-user";
-var METADATA_HEADER_EXTERNAL = "netlify-blobs-metadata";
+import {
+	base64Decode as base64Decode2,
+	base64Encode as base64Encode2,
+} from '@netlify/runtime-utils';
+var BASE64_PREFIX = 'b64;';
+var METADATA_HEADER_INTERNAL = 'x-amz-meta-user';
+var METADATA_HEADER_EXTERNAL = 'netlify-blobs-metadata';
 var METADATA_MAX_SIZE = 2 * 1024;
 var encodeMetadata = (metadata) => {
-  if (!metadata) {
-    return null;
-  }
-  const encodedObject = base64Encode2(JSON.stringify(metadata));
-  const payload = `b64;${encodedObject}`;
-  if (METADATA_HEADER_EXTERNAL.length + payload.length > METADATA_MAX_SIZE) {
-    throw new Error("Metadata object exceeds the maximum size");
-  }
-  return payload;
+	if (!metadata) {
+		return null;
+	}
+	const encodedObject = base64Encode2(JSON.stringify(metadata));
+	const payload = `b64;${encodedObject}`;
+	if (METADATA_HEADER_EXTERNAL.length + payload.length > METADATA_MAX_SIZE) {
+		throw new Error('Metadata object exceeds the maximum size');
+	}
+	return payload;
 };
 var decodeMetadata = (header) => {
-  if (!header?.startsWith(BASE64_PREFIX)) {
-    return {};
-  }
-  const encodedData = header.slice(BASE64_PREFIX.length);
-  const decodedData = base64Decode2(encodedData);
-  const metadata = JSON.parse(decodedData);
-  return metadata;
+	if (!header?.startsWith(BASE64_PREFIX)) {
+		return {};
+	}
+	const encodedData = header.slice(BASE64_PREFIX.length);
+	const decodedData = base64Decode2(encodedData);
+	const metadata = JSON.parse(decodedData);
+	return metadata;
 };
 var getMetadataFromResponse = (response) => {
-  if (!response.headers) {
-    return {};
-  }
-  const value = response.headers.get(METADATA_HEADER_EXTERNAL) || response.headers.get(METADATA_HEADER_INTERNAL);
-  try {
-    return decodeMetadata(value);
-  } catch {
-    throw new Error(
-      "An internal error occurred while trying to retrieve the metadata for an entry. Please try updating to the latest version of the Netlify Blobs client."
-    );
-  }
+	if (!response.headers) {
+		return {};
+	}
+	const value =
+		response.headers.get(METADATA_HEADER_EXTERNAL) ||
+		response.headers.get(METADATA_HEADER_INTERNAL);
+	try {
+		return decodeMetadata(value);
+	} catch {
+		throw new Error(
+			'An internal error occurred while trying to retrieve the metadata for an entry. Please try updating to the latest version of the Netlify Blobs client.',
+		);
+	}
 };
 
 // src/util.ts
-import process from "process";
+import process from 'process';
 
 // src/headers.ts
-var NF_ERROR = "x-nf-error";
-var NF_REQUEST_ID = "x-nf-request-id";
+var NF_ERROR = 'x-nf-error';
+var NF_REQUEST_ID = 'x-nf-request-id';
 
 // src/util.ts
 var BlobsInternalError = class extends Error {
-  constructor(res) {
-    let details = res.headers.get(NF_ERROR) || `${res.status} status code`;
-    if (res.headers.has(NF_REQUEST_ID)) {
-      details += `, ID: ${res.headers.get(NF_REQUEST_ID)}`;
-    }
-    super(`Netlify Blobs has generated an internal error (${details})`);
-    this.name = "BlobsInternalError";
-  }
+	constructor(res) {
+		let details = res.headers.get(NF_ERROR) || `${res.status} status code`;
+		if (res.headers.has(NF_REQUEST_ID)) {
+			details += `, ID: ${res.headers.get(NF_REQUEST_ID)}`;
+		}
+		super(`Netlify Blobs has generated an internal error (${details})`);
+		this.name = 'BlobsInternalError';
+	}
 };
 var collectIterator = async (iterator) => {
-  const result = [];
-  for await (const item of iterator) {
-    result.push(item);
-  }
-  return result;
+	const result = [];
+	for await (const item of iterator) {
+		result.push(item);
+	}
+	return result;
 };
 var isNodeError = (error) => error instanceof Error;
 function percentEncode(str) {
-  return str.replace(/./, (char) => {
-    return "%" + char.charCodeAt(0).toString(16).padStart(2, "0");
-  });
+	return str.replace(/./, (char) => {
+		return '%' + char.charCodeAt(0).toString(16).padStart(2, '0');
+	});
 }
 var invalidWin32File = /^(CON|COM[1-9]|LPT[1-9]|NUL|PRN|AUX)$/i;
 function encodeWin32SafeName(string) {
-  if (invalidWin32File.exec(string)) {
-    return percentEncode(string);
-  }
-  return encodeURIComponent(string).replace(/([*]|[. ]$)/g, percentEncode);
+	if (invalidWin32File.exec(string)) {
+		return percentEncode(string);
+	}
+	return encodeURIComponent(string).replace(/([*]|[. ]$)/g, percentEncode);
 }
 function decodeWin32SafeName(string) {
-  return decodeURIComponent(string);
+	return decodeURIComponent(string);
 }
 function encodeName(string) {
-  return process.platform == "win32" ? encodeWin32SafeName(string) : string;
+	return encodeWin32SafeName(string);
 }
 function decodeName(string) {
-  return process.platform == "win32" ? decodeWin32SafeName(string) : string;
+	return decodeWin32SafeName(string);
 }
 
 // src/consistency.ts
 var BlobsConsistencyError = class extends Error {
-  constructor() {
-    super(
-      `Netlify Blobs has failed to perform a read using strong consistency because the environment has not been configured with a 'uncachedEdgeURL' property`
-    );
-    this.name = "BlobsConsistencyError";
-  }
+	constructor() {
+		super(
+			`Netlify Blobs has failed to perform a read using strong consistency because the environment has not been configured with a 'uncachedEdgeURL' property`,
+		);
+		this.name = 'BlobsConsistencyError';
+	}
 };
 
 // src/region.ts
-var REGION_AUTO = "auto";
+var REGION_AUTO = 'auto';
 var regions = {
-  "us-east-1": true,
-  "us-east-2": true,
-  "eu-central-1": true,
-  "ap-southeast-1": true,
-  "ap-southeast-2": true
+	'us-east-1': true,
+	'us-east-2': true,
+	'eu-central-1': true,
+	'ap-southeast-1': true,
+	'ap-southeast-2': true,
 };
 var isValidRegion = (input) => Object.keys(regions).includes(input);
 var InvalidBlobsRegionError = class extends Error {
-  constructor(region) {
-    super(
-      `${region} is not a supported Netlify Blobs region. Supported values are: ${Object.keys(regions).join(", ")}.`
-    );
-    this.name = "InvalidBlobsRegionError";
-  }
+	constructor(region) {
+		super(
+			`${region} is not a supported Netlify Blobs region. Supported values are: ${Object.keys(regions).join(', ')}.`,
+		);
+		this.name = 'InvalidBlobsRegionError';
+	}
 };
 
 // src/retry.ts
-var DEFAULT_RETRY_DELAY = getEnvironment().get("NODE_ENV") === "test" ? 1 : 5e3;
+var DEFAULT_RETRY_DELAY = getEnvironment().get('NODE_ENV') === 'test' ? 1 : 5e3;
 var MIN_RETRY_DELAY = 1e3;
 var MAX_RETRY = 5;
-var RATE_LIMIT_HEADER = "X-RateLimit-Reset";
+var RATE_LIMIT_HEADER = 'X-RateLimit-Reset';
 var fetchAndRetry = async (fetch, url, options, attemptsLeft = MAX_RETRY) => {
-  try {
-    const res = await fetch(url, options);
-    if (attemptsLeft > 0 && (res.status === 429 || res.status >= 500)) {
-      const delay = getDelay(res.headers.get(RATE_LIMIT_HEADER));
-      await sleep(delay);
-      return fetchAndRetry(fetch, url, options, attemptsLeft - 1);
-    }
-    return res;
-  } catch (error) {
-    if (attemptsLeft === 0) {
-      throw error;
-    }
-    const delay = getDelay();
-    await sleep(delay);
-    return fetchAndRetry(fetch, url, options, attemptsLeft - 1);
-  }
+	try {
+		const res = await fetch(url, options);
+		if (attemptsLeft > 0 && (res.status === 429 || res.status >= 500)) {
+			const delay = getDelay(res.headers.get(RATE_LIMIT_HEADER));
+			await sleep(delay);
+			return fetchAndRetry(fetch, url, options, attemptsLeft - 1);
+		}
+		return res;
+	} catch (error) {
+		if (attemptsLeft === 0) {
+			throw error;
+		}
+		const delay = getDelay();
+		await sleep(delay);
+		return fetchAndRetry(fetch, url, options, attemptsLeft - 1);
+	}
 };
 var getDelay = (rateLimitReset) => {
-  if (!rateLimitReset) {
-    return DEFAULT_RETRY_DELAY;
-  }
-  return Math.max(Number(rateLimitReset) * 1e3 - Date.now(), MIN_RETRY_DELAY);
+	if (!rateLimitReset) {
+		return DEFAULT_RETRY_DELAY;
+	}
+	return Math.max(Number(rateLimitReset) * 1e3 - Date.now(), MIN_RETRY_DELAY);
 };
-var sleep = (ms) => new Promise((resolve) => {
-  setTimeout(resolve, ms);
-});
+var sleep = (ms) =>
+	new Promise((resolve) => {
+		setTimeout(resolve, ms);
+	});
 
 // src/client.ts
-var SIGNED_URL_ACCEPT_HEADER = "application/json;type=signed-url";
+var SIGNED_URL_ACCEPT_HEADER = 'application/json;type=signed-url';
 var Client = class {
-  constructor({ apiURL, consistency, edgeURL, fetch, region, siteID, token, uncachedEdgeURL }) {
-    this.apiURL = apiURL;
-    this.consistency = consistency ?? "eventual";
-    this.edgeURL = edgeURL;
-    this.fetch = fetch ?? globalThis.fetch;
-    this.region = region;
-    this.siteID = siteID;
-    this.token = token;
-    this.uncachedEdgeURL = uncachedEdgeURL;
-    if (!this.fetch) {
-      throw new Error(
-        "Netlify Blobs could not find a `fetch` client in the global scope. You can either update your runtime to a version that includes `fetch` (like Node.js 18.0.0 or above), or you can supply your own implementation using the `fetch` property."
-      );
-    }
-  }
-  async getFinalRequest({
-    consistency: opConsistency,
-    key,
-    metadata,
-    method,
-    parameters = {},
-    storeName
-  }) {
-    const encodedMetadata = encodeMetadata(metadata);
-    const consistency = opConsistency ?? this.consistency;
-    let urlPath = `/${this.siteID}`;
-    if (storeName) {
-      urlPath += `/${storeName}`;
-    }
-    if (key) {
-      urlPath += `/${key}`;
-    }
-    if (this.edgeURL) {
-      if (consistency === "strong" && !this.uncachedEdgeURL) {
-        throw new BlobsConsistencyError();
-      }
-      const headers = {
-        authorization: `Bearer ${this.token}`
-      };
-      if (encodedMetadata) {
-        headers[METADATA_HEADER_INTERNAL] = encodedMetadata;
-      }
-      if (this.region) {
-        urlPath = `/region:${this.region}${urlPath}`;
-      }
-      const url2 = new URL(urlPath, consistency === "strong" ? this.uncachedEdgeURL : this.edgeURL);
-      for (const key2 in parameters) {
-        url2.searchParams.set(key2, parameters[key2]);
-      }
-      return {
-        headers,
-        url: url2.toString()
-      };
-    }
-    const apiHeaders = { authorization: `Bearer ${this.token}` };
-    const url = new URL(`/api/v1/blobs${urlPath}`, this.apiURL ?? "https://api.netlify.com");
-    for (const key2 in parameters) {
-      url.searchParams.set(key2, parameters[key2]);
-    }
-    if (this.region) {
-      url.searchParams.set("region", this.region);
-    }
-    if (storeName === void 0 || key === void 0) {
-      return {
-        headers: apiHeaders,
-        url: url.toString()
-      };
-    }
-    if (encodedMetadata) {
-      apiHeaders[METADATA_HEADER_EXTERNAL] = encodedMetadata;
-    }
-    if (method === "head" /* HEAD */ || method === "delete" /* DELETE */) {
-      return {
-        headers: apiHeaders,
-        url: url.toString()
-      };
-    }
-    const res = await this.fetch(url.toString(), {
-      headers: { ...apiHeaders, accept: SIGNED_URL_ACCEPT_HEADER },
-      method
-    });
-    if (res.status !== 200) {
-      throw new BlobsInternalError(res);
-    }
-    const { url: signedURL } = await res.json();
-    const userHeaders = encodedMetadata ? { [METADATA_HEADER_INTERNAL]: encodedMetadata } : void 0;
-    return {
-      headers: userHeaders,
-      url: signedURL
-    };
-  }
-  async makeRequest({
-    body,
-    conditions = {},
-    consistency,
-    headers: extraHeaders,
-    key,
-    metadata,
-    method,
-    parameters,
-    storeName
-  }) {
-    const { headers: baseHeaders = {}, url } = await this.getFinalRequest({
-      consistency,
-      key,
-      metadata,
-      method,
-      parameters,
-      storeName
-    });
-    const headers = {
-      ...baseHeaders,
-      ...extraHeaders
-    };
-    if (method === "put" /* PUT */) {
-      headers["cache-control"] = "max-age=0, stale-while-revalidate=60";
-    }
-    if ("onlyIfMatch" in conditions && conditions.onlyIfMatch) {
-      headers["if-match"] = conditions.onlyIfMatch;
-    } else if ("onlyIfNew" in conditions && conditions.onlyIfNew) {
-      headers["if-none-match"] = "*";
-    }
-    const options = {
-      body,
-      headers,
-      method
-    };
-    if (body instanceof ReadableStream) {
-      options.duplex = "half";
-    }
-    return fetchAndRetry(this.fetch, url, options);
-  }
+	constructor({ apiURL, consistency, edgeURL, fetch, region, siteID, token, uncachedEdgeURL }) {
+		this.apiURL = apiURL;
+		this.consistency = consistency ?? 'eventual';
+		this.edgeURL = edgeURL;
+		this.fetch = fetch ?? globalThis.fetch;
+		this.region = region;
+		this.siteID = siteID;
+		this.token = token;
+		this.uncachedEdgeURL = uncachedEdgeURL;
+		if (!this.fetch) {
+			throw new Error(
+				'Netlify Blobs could not find a `fetch` client in the global scope. You can either update your runtime to a version that includes `fetch` (like Node.js 18.0.0 or above), or you can supply your own implementation using the `fetch` property.',
+			);
+		}
+	}
+	async getFinalRequest({
+		consistency: opConsistency,
+		key,
+		metadata,
+		method,
+		parameters = {},
+		storeName,
+	}) {
+		const encodedMetadata = encodeMetadata(metadata);
+		const consistency = opConsistency ?? this.consistency;
+		let urlPath = `/${this.siteID}`;
+		if (storeName) {
+			urlPath += `/${storeName}`;
+		}
+		if (key) {
+			urlPath += `/${key}`;
+		}
+		if (this.edgeURL) {
+			if (consistency === 'strong' && !this.uncachedEdgeURL) {
+				throw new BlobsConsistencyError();
+			}
+			const headers = {
+				authorization: `Bearer ${this.token}`,
+			};
+			if (encodedMetadata) {
+				headers[METADATA_HEADER_INTERNAL] = encodedMetadata;
+			}
+			if (this.region) {
+				urlPath = `/region:${this.region}${urlPath}`;
+			}
+			const url2 = new URL(urlPath, consistency === 'strong' ? this.uncachedEdgeURL : this.edgeURL);
+			for (const key2 in parameters) {
+				url2.searchParams.set(key2, parameters[key2]);
+			}
+			return {
+				headers,
+				url: url2.toString(),
+			};
+		}
+		const apiHeaders = { authorization: `Bearer ${this.token}` };
+		const url = new URL(`/api/v1/blobs${urlPath}`, this.apiURL ?? 'https://api.netlify.com');
+		for (const key2 in parameters) {
+			url.searchParams.set(key2, parameters[key2]);
+		}
+		if (this.region) {
+			url.searchParams.set('region', this.region);
+		}
+		if (storeName === void 0 || key === void 0) {
+			return {
+				headers: apiHeaders,
+				url: url.toString(),
+			};
+		}
+		if (encodedMetadata) {
+			apiHeaders[METADATA_HEADER_EXTERNAL] = encodedMetadata;
+		}
+		if (method === 'head' /* HEAD */ || method === 'delete' /* DELETE */) {
+			return {
+				headers: apiHeaders,
+				url: url.toString(),
+			};
+		}
+		const res = await this.fetch(url.toString(), {
+			headers: { ...apiHeaders, accept: SIGNED_URL_ACCEPT_HEADER },
+			method,
+		});
+		if (res.status !== 200) {
+			throw new BlobsInternalError(res);
+		}
+		const { url: signedURL } = await res.json();
+		const userHeaders = encodedMetadata ? { [METADATA_HEADER_INTERNAL]: encodedMetadata } : void 0;
+		return {
+			headers: userHeaders,
+			url: signedURL,
+		};
+	}
+	async makeRequest({
+		body,
+		conditions = {},
+		consistency,
+		headers: extraHeaders,
+		key,
+		metadata,
+		method,
+		parameters,
+		storeName,
+	}) {
+		const { headers: baseHeaders = {}, url } = await this.getFinalRequest({
+			consistency,
+			key,
+			metadata,
+			method,
+			parameters,
+			storeName,
+		});
+		const headers = {
+			...baseHeaders,
+			...extraHeaders,
+		};
+		if (method === 'put' /* PUT */) {
+			headers['cache-control'] = 'max-age=0, stale-while-revalidate=60';
+		}
+		if ('onlyIfMatch' in conditions && conditions.onlyIfMatch) {
+			headers['if-match'] = conditions.onlyIfMatch;
+		} else if ('onlyIfNew' in conditions && conditions.onlyIfNew) {
+			headers['if-none-match'] = '*';
+		}
+		const options = {
+			body,
+			headers,
+			method,
+		};
+		if (body instanceof ReadableStream) {
+			options.duplex = 'half';
+		}
+		return fetchAndRetry(this.fetch, url, options);
+	}
 };
 var getClientOptions = (options, contextOverride) => {
-  const context = contextOverride ?? getEnvironmentContext();
-  const siteID = context.siteID ?? options.siteID;
-  const token = context.token ?? options.token;
-  if (!siteID || !token) {
-    throw new MissingBlobsEnvironmentError(["siteID", "token"]);
-  }
-  if (options.region !== void 0 && !isValidRegion(options.region)) {
-    throw new InvalidBlobsRegionError(options.region);
-  }
-  const clientOptions = {
-    apiURL: context.apiURL ?? options.apiURL,
-    consistency: options.consistency,
-    edgeURL: context.edgeURL ?? options.edgeURL,
-    fetch: options.fetch,
-    region: options.region,
-    siteID,
-    token,
-    uncachedEdgeURL: context.uncachedEdgeURL ?? options.uncachedEdgeURL
-  };
-  return clientOptions;
+	const context = contextOverride ?? getEnvironmentContext();
+	const siteID = context.siteID ?? options.siteID;
+	const token = context.token ?? options.token;
+	if (!siteID || !token) {
+		throw new MissingBlobsEnvironmentError(['siteID', 'token']);
+	}
+	if (options.region !== void 0 && !isValidRegion(options.region)) {
+		throw new InvalidBlobsRegionError(options.region);
+	}
+	const clientOptions = {
+		apiURL: context.apiURL ?? options.apiURL,
+		consistency: options.consistency,
+		edgeURL: context.edgeURL ?? options.edgeURL,
+		fetch: options.fetch,
+		region: options.region,
+		siteID,
+		token,
+		uncachedEdgeURL: context.uncachedEdgeURL ?? options.uncachedEdgeURL,
+	};
+	return clientOptions;
 };
 
 export {
-  getEnvironmentContext,
-  setEnvironmentContext,
-  MissingBlobsEnvironmentError,
-  METADATA_HEADER_INTERNAL,
-  encodeMetadata,
-  decodeMetadata,
-  getMetadataFromResponse,
-  REGION_AUTO,
-  BlobsInternalError,
-  collectIterator,
-  isNodeError,
-  encodeName,
-  decodeName,
-  SIGNED_URL_ACCEPT_HEADER,
-  Client,
-  getClientOptions
+	getEnvironmentContext,
+	setEnvironmentContext,
+	MissingBlobsEnvironmentError,
+	METADATA_HEADER_INTERNAL,
+	encodeMetadata,
+	decodeMetadata,
+	getMetadataFromResponse,
+	REGION_AUTO,
+	BlobsInternalError,
+	collectIterator,
+	isNodeError,
+	encodeName,
+	decodeName,
+	SIGNED_URL_ACCEPT_HEADER,
+	Client,
+	getClientOptions,
 };
diff --git a/dist/main.js b/dist/main.js
index 469fd84fdb254b9f662f28b1c5a6203bceef832b..a5ff89c4a287b4cf142216fb5fe499b058fe85b0 100644
--- a/dist/main.js
+++ b/dist/main.js
@@ -1,450 +1,487 @@
 import {
-  BlobsInternalError,
-  Client,
-  MissingBlobsEnvironmentError,
-  REGION_AUTO,
-  collectIterator,
-  getClientOptions,
-  getEnvironmentContext,
-  getMetadataFromResponse,
-  setEnvironmentContext
-} from "./chunk-HN33TXZT.js";
+	BlobsInternalError,
+	Client,
+	MissingBlobsEnvironmentError,
+	REGION_AUTO,
+	collectIterator,
+	getClientOptions,
+	getEnvironmentContext,
+	getMetadataFromResponse,
+	setEnvironmentContext,
+} from './chunk-HN33TXZT.js';
 
 // src/lambda_compat.ts
-import { base64Decode } from "@netlify/runtime-utils";
+import { base64Decode } from '@netlify/runtime-utils';
 var connectLambda = (event) => {
-  const rawData = base64Decode(event.blobs);
-  const data = JSON.parse(rawData);
-  const environmentContext = {
-    deployID: event.headers["x-nf-deploy-id"],
-    edgeURL: data.url,
-    siteID: event.headers["x-nf-site-id"],
-    token: data.token
-  };
-  setEnvironmentContext(environmentContext);
+	const rawData = base64Decode(event.blobs);
+	const data = JSON.parse(rawData);
+	const environmentContext = {
+		deployID: event.headers['x-nf-deploy-id'],
+		edgeURL: data.url,
+		siteID: event.headers['x-nf-site-id'],
+		token: data.token,
+	};
+	setEnvironmentContext(environmentContext);
 };
 
 // src/store.ts
-var DEPLOY_STORE_PREFIX = "deploy:";
-var LEGACY_STORE_INTERNAL_PREFIX = "netlify-internal/legacy-namespace/";
-var SITE_STORE_PREFIX = "site:";
+var DEPLOY_STORE_PREFIX = 'deploy:';
+var LEGACY_STORE_INTERNAL_PREFIX = 'netlify-internal/legacy-namespace/';
+var SITE_STORE_PREFIX = 'site:';
 var STATUS_OK = 200;
 var STATUS_PRE_CONDITION_FAILED = 412;
 var Store = class _Store {
-  constructor(options) {
-    this.client = options.client;
-    if ("deployID" in options) {
-      _Store.validateDeployID(options.deployID);
-      let name = DEPLOY_STORE_PREFIX + options.deployID;
-      if (options.name) {
-        name += `:${options.name}`;
-      }
-      this.name = name;
-    } else if (options.name.startsWith(LEGACY_STORE_INTERNAL_PREFIX)) {
-      const storeName = options.name.slice(LEGACY_STORE_INTERNAL_PREFIX.length);
-      _Store.validateStoreName(storeName);
-      this.name = storeName;
-    } else {
-      _Store.validateStoreName(options.name);
-      this.name = SITE_STORE_PREFIX + options.name;
-    }
-  }
-  async delete(key) {
-    const res = await this.client.makeRequest({ key, method: "delete" /* DELETE */, storeName: this.name });
-    if (![200, 204, 404].includes(res.status)) {
-      throw new BlobsInternalError(res);
-    }
-  }
-  async get(key, options) {
-    const { consistency, type } = options ?? {};
-    const res = await this.client.makeRequest({ consistency, key, method: "get" /* GET */, storeName: this.name });
-    if (res.status === 404) {
-      return null;
-    }
-    if (res.status !== 200) {
-      throw new BlobsInternalError(res);
-    }
-    if (type === void 0 || type === "text") {
-      return res.text();
-    }
-    if (type === "arrayBuffer") {
-      return res.arrayBuffer();
-    }
-    if (type === "blob") {
-      return res.blob();
-    }
-    if (type === "json") {
-      return res.json();
-    }
-    if (type === "stream") {
-      return res.body;
-    }
-    throw new BlobsInternalError(res);
-  }
-  async getMetadata(key, { consistency } = {}) {
-    const res = await this.client.makeRequest({ consistency, key, method: "head" /* HEAD */, storeName: this.name });
-    if (res.status === 404) {
-      return null;
-    }
-    if (res.status !== 200 && res.status !== 304) {
-      throw new BlobsInternalError(res);
-    }
-    const etag = res?.headers.get("etag") ?? void 0;
-    const metadata = getMetadataFromResponse(res);
-    const result = {
-      etag,
-      metadata
-    };
-    return result;
-  }
-  async getWithMetadata(key, options) {
-    const { consistency, etag: requestETag, type } = options ?? {};
-    const headers = requestETag ? { "if-none-match": requestETag } : void 0;
-    const res = await this.client.makeRequest({
-      consistency,
-      headers,
-      key,
-      method: "get" /* GET */,
-      storeName: this.name
-    });
-    if (res.status === 404) {
-      return null;
-    }
-    if (res.status !== 200 && res.status !== 304) {
-      throw new BlobsInternalError(res);
-    }
-    const responseETag = res?.headers.get("etag") ?? void 0;
-    const metadata = getMetadataFromResponse(res);
-    const result = {
-      etag: responseETag,
-      metadata
-    };
-    if (res.status === 304 && requestETag) {
-      return { data: null, ...result };
-    }
-    if (type === void 0 || type === "text") {
-      return { data: await res.text(), ...result };
-    }
-    if (type === "arrayBuffer") {
-      return { data: await res.arrayBuffer(), ...result };
-    }
-    if (type === "blob") {
-      return { data: await res.blob(), ...result };
-    }
-    if (type === "json") {
-      return { data: await res.json(), ...result };
-    }
-    if (type === "stream") {
-      return { data: res.body, ...result };
-    }
-    throw new Error(`Invalid 'type' property: ${type}. Expected: arrayBuffer, blob, json, stream, or text.`);
-  }
-  list(options = {}) {
-    const iterator = this.getListIterator(options);
-    if (options.paginate) {
-      return iterator;
-    }
-    return collectIterator(iterator).then(
-      (items) => items.reduce(
-        (acc, item) => ({
-          blobs: [...acc.blobs, ...item.blobs],
-          directories: [...acc.directories, ...item.directories]
-        }),
-        { blobs: [], directories: [] }
-      )
-    );
-  }
-  async set(key, data, options = {}) {
-    _Store.validateKey(key);
-    const conditions = _Store.getConditions(options);
-    const res = await this.client.makeRequest({
-      conditions,
-      body: data,
-      key,
-      metadata: options.metadata,
-      method: "put" /* PUT */,
-      storeName: this.name
-    });
-    const etag = res.headers.get("etag") ?? "";
-    if (conditions) {
-      return res.status === STATUS_PRE_CONDITION_FAILED ? { modified: false } : { etag, modified: true };
-    }
-    if (res.status === STATUS_OK) {
-      return {
-        etag,
-        modified: true
-      };
-    }
-    throw new BlobsInternalError(res);
-  }
-  async setJSON(key, data, options = {}) {
-    _Store.validateKey(key);
-    const conditions = _Store.getConditions(options);
-    const payload = JSON.stringify(data);
-    const headers = {
-      "content-type": "application/json"
-    };
-    const res = await this.client.makeRequest({
-      ...conditions,
-      body: payload,
-      headers,
-      key,
-      metadata: options.metadata,
-      method: "put" /* PUT */,
-      storeName: this.name
-    });
-    const etag = res.headers.get("etag") ?? "";
-    if (conditions) {
-      return res.status === STATUS_PRE_CONDITION_FAILED ? { modified: false } : { etag, modified: true };
-    }
-    if (res.status === STATUS_OK) {
-      return {
-        etag,
-        modified: true
-      };
-    }
-    throw new BlobsInternalError(res);
-  }
-  static formatListResultBlob(result) {
-    if (!result.key) {
-      return null;
-    }
-    return {
-      etag: result.etag,
-      key: result.key
-    };
-  }
-  static getConditions(options) {
-    if ("onlyIfMatch" in options && "onlyIfNew" in options) {
-      throw new Error(
-        `The 'onlyIfMatch' and 'onlyIfNew' options are mutually exclusive. Using 'onlyIfMatch' will make the write succeed only if there is an entry for the key with the given content, while 'onlyIfNew' will make the write succeed only if there is no entry for the key.`
-      );
-    }
-    if ("onlyIfMatch" in options && options.onlyIfMatch) {
-      if (typeof options.onlyIfMatch !== "string") {
-        throw new Error(`The 'onlyIfMatch' property expects a string representing an ETag.`);
-      }
-      return {
-        onlyIfMatch: options.onlyIfMatch
-      };
-    }
-    if ("onlyIfNew" in options && options.onlyIfNew) {
-      if (typeof options.onlyIfNew !== "boolean") {
-        throw new Error(
-          `The 'onlyIfNew' property expects a boolean indicating whether the write should fail if an entry for the key already exists.`
-        );
-      }
-      return {
-        onlyIfNew: true
-      };
-    }
-  }
-  static validateKey(key) {
-    if (key === "") {
-      throw new Error("Blob key must not be empty.");
-    }
-    if (key.startsWith("/") || key.startsWith("%2F")) {
-      throw new Error("Blob key must not start with forward slash (/).");
-    }
-    if (new TextEncoder().encode(key).length > 600) {
-      throw new Error(
-        "Blob key must be a sequence of Unicode characters whose UTF-8 encoding is at most 600 bytes long."
-      );
-    }
-  }
-  static validateDeployID(deployID) {
-    if (!/^\w{1,24}$/.test(deployID)) {
-      throw new Error(`'${deployID}' is not a valid Netlify deploy ID.`);
-    }
-  }
-  static validateStoreName(name) {
-    if (name.includes("/") || name.includes("%2F")) {
-      throw new Error("Store name must not contain forward slashes (/).");
-    }
-    if (new TextEncoder().encode(name).length > 64) {
-      throw new Error(
-        "Store name must be a sequence of Unicode characters whose UTF-8 encoding is at most 64 bytes long."
-      );
-    }
-  }
-  getListIterator(options) {
-    const { client, name: storeName } = this;
-    const parameters = {};
-    if (options?.prefix) {
-      parameters.prefix = options.prefix;
-    }
-    if (options?.directories) {
-      parameters.directories = "true";
-    }
-    return {
-      [Symbol.asyncIterator]() {
-        let currentCursor = null;
-        let done = false;
-        return {
-          async next() {
-            if (done) {
-              return { done: true, value: void 0 };
-            }
-            const nextParameters = { ...parameters };
-            if (currentCursor !== null) {
-              nextParameters.cursor = currentCursor;
-            }
-            const res = await client.makeRequest({
-              method: "get" /* GET */,
-              parameters: nextParameters,
-              storeName
-            });
-            let blobs = [];
-            let directories = [];
-            if (![200, 204, 404].includes(res.status)) {
-              throw new BlobsInternalError(res);
-            }
-            if (res.status === 404) {
-              done = true;
-            } else {
-              const page = await res.json();
-              if (page.next_cursor) {
-                currentCursor = page.next_cursor;
-              } else {
-                done = true;
-              }
-              blobs = (page.blobs ?? []).map(_Store.formatListResultBlob).filter(Boolean);
-              directories = page.directories ?? [];
-            }
-            return {
-              done: false,
-              value: {
-                blobs,
-                directories
-              }
-            };
-          }
-        };
-      }
-    };
-  }
+	constructor(options) {
+		this.client = options.client;
+		if ('deployID' in options) {
+			_Store.validateDeployID(options.deployID);
+			let name = DEPLOY_STORE_PREFIX + options.deployID;
+			if (options.name) {
+				name += `:${options.name}`;
+			}
+			this.name = name;
+		} else if (options.name.startsWith(LEGACY_STORE_INTERNAL_PREFIX)) {
+			const storeName = options.name.slice(LEGACY_STORE_INTERNAL_PREFIX.length);
+			_Store.validateStoreName(storeName);
+			this.name = storeName;
+		} else {
+			_Store.validateStoreName(options.name);
+			this.name = SITE_STORE_PREFIX + options.name;
+		}
+	}
+	async delete(key) {
+		const res = await this.client.makeRequest({
+			key,
+			method: 'delete' /* DELETE */,
+			storeName: this.name,
+		});
+		if (![200, 204, 404].includes(res.status)) {
+			throw new BlobsInternalError(res);
+		}
+	}
+	async get(key, options) {
+		const { consistency, type } = options ?? {};
+		const res = await this.client.makeRequest({
+			consistency,
+			key,
+			method: 'get' /* GET */,
+			storeName: this.name,
+		});
+		if (res.status === 404) {
+			return null;
+		}
+		if (res.status !== 200) {
+			throw new BlobsInternalError(res);
+		}
+		if (type === void 0 || type === 'text') {
+			return res.text();
+		}
+		if (type === 'arrayBuffer') {
+			return res.arrayBuffer();
+		}
+		if (type === 'blob') {
+			return res.blob();
+		}
+		if (type === 'json') {
+			return res.json();
+		}
+		if (type === 'stream') {
+			return res.body;
+		}
+		throw new BlobsInternalError(res);
+	}
+	async getMetadata(key, { consistency } = {}) {
+		const res = await this.client.makeRequest({
+			consistency,
+			key,
+			method: 'head' /* HEAD */,
+			storeName: this.name,
+		});
+		if (res.status === 404) {
+			return null;
+		}
+		if (res.status !== 200 && res.status !== 304) {
+			throw new BlobsInternalError(res);
+		}
+		const etag = res?.headers.get('etag') ?? void 0;
+		const metadata = getMetadataFromResponse(res);
+		const result = {
+			etag,
+			metadata,
+		};
+		return result;
+	}
+	async getWithMetadata(key, options) {
+		const { consistency, etag: requestETag, type } = options ?? {};
+		const headers = requestETag ? { 'if-none-match': requestETag } : void 0;
+		const res = await this.client.makeRequest({
+			consistency,
+			headers,
+			key,
+			method: 'get' /* GET */,
+			storeName: this.name,
+		});
+		if (res.status === 404) {
+			return null;
+		}
+		if (res.status !== 200 && res.status !== 304) {
+			throw new BlobsInternalError(res);
+		}
+		const responseETag = res?.headers.get('etag') ?? void 0;
+		const metadata = getMetadataFromResponse(res);
+		const result = {
+			etag: responseETag,
+			metadata,
+		};
+		if (res.status === 304 && requestETag) {
+			return { data: null, ...result };
+		}
+		if (type === void 0 || type === 'text') {
+			return { data: await res.text(), ...result };
+		}
+		if (type === 'arrayBuffer') {
+			return { data: await res.arrayBuffer(), ...result };
+		}
+		if (type === 'blob') {
+			return { data: await res.blob(), ...result };
+		}
+		if (type === 'json') {
+			return { data: await res.json(), ...result };
+		}
+		if (type === 'stream') {
+			return { data: res.body, ...result };
+		}
+		throw new Error(
+			`Invalid 'type' property: ${type}. Expected: arrayBuffer, blob, json, stream, or text.`,
+		);
+	}
+	list(options = {}) {
+		const iterator = this.getListIterator(options);
+		if (options.paginate) {
+			return iterator;
+		}
+		return collectIterator(iterator).then((items) =>
+			items.reduce(
+				(acc, item) => ({
+					blobs: [...acc.blobs, ...item.blobs],
+					directories: [...acc.directories, ...item.directories],
+				}),
+				{ blobs: [], directories: [] },
+			),
+		);
+	}
+	async set(key, data, options = {}) {
+		console.log('setting: ', key);
+		_Store.validateKey(key);
+		const conditions = _Store.getConditions(options);
+		const res = await this.client.makeRequest({
+			conditions,
+			body: data,
+			key,
+			metadata: options.metadata,
+			method: 'put' /* PUT */,
+			storeName: this.name,
+		});
+		const etag = res.headers.get('etag') ?? '';
+		if (conditions) {
+			return res.status === STATUS_PRE_CONDITION_FAILED
+				? { modified: false }
+				: { etag, modified: true };
+		}
+		if (res.status === STATUS_OK) {
+			return {
+				etag,
+				modified: true,
+			};
+		}
+		console.error('RES:');
+		console.error(res);
+		console.error('COND:');
+		console.error(conditions);
+		console.error('BODY:');
+		console.error(data);
+		console.error('METADATA:');
+		console.error(options.metadata);
+		console.error('STORE NAME:');
+		console.error(this.name);
+		throw new BlobsInternalError(res);
+	}
+	async setJSON(key, data, options = {}) {
+		console.log('setting json:', key);
+		_Store.validateKey(key);
+		const conditions = _Store.getConditions(options);
+		const payload = JSON.stringify(data);
+		const headers = {
+			'content-type': 'application/json',
+		};
+		const res = await this.client.makeRequest({
+			...conditions,
+			body: payload,
+			headers,
+			key,
+			metadata: options.metadata,
+			method: 'put' /* PUT */,
+			storeName: this.name,
+		});
+		const etag = res.headers.get('etag') ?? '';
+		if (conditions) {
+			return res.status === STATUS_PRE_CONDITION_FAILED
+				? { modified: false }
+				: { etag, modified: true };
+		}
+		if (res.status === STATUS_OK) {
+			return {
+				etag,
+				modified: true,
+			};
+		}
+		throw new BlobsInternalError(res);
+	}
+	static formatListResultBlob(result) {
+		if (!result.key) {
+			return null;
+		}
+		return {
+			etag: result.etag,
+			key: result.key,
+		};
+	}
+	static getConditions(options) {
+		if ('onlyIfMatch' in options && 'onlyIfNew' in options) {
+			throw new Error(
+				`The 'onlyIfMatch' and 'onlyIfNew' options are mutually exclusive. Using 'onlyIfMatch' will make the write succeed only if there is an entry for the key with the given content, while 'onlyIfNew' will make the write succeed only if there is no entry for the key.`,
+			);
+		}
+		if ('onlyIfMatch' in options && options.onlyIfMatch) {
+			if (typeof options.onlyIfMatch !== 'string') {
+				throw new Error(`The 'onlyIfMatch' property expects a string representing an ETag.`);
+			}
+			return {
+				onlyIfMatch: options.onlyIfMatch,
+			};
+		}
+		if ('onlyIfNew' in options && options.onlyIfNew) {
+			if (typeof options.onlyIfNew !== 'boolean') {
+				throw new Error(
+					`The 'onlyIfNew' property expects a boolean indicating whether the write should fail if an entry for the key already exists.`,
+				);
+			}
+			return {
+				onlyIfNew: true,
+			};
+		}
+	}
+	static validateKey(key) {
+		if (key === '') {
+			throw new Error('Blob key must not be empty.');
+		}
+		if (key.startsWith('/') || key.startsWith('%2F')) {
+			throw new Error('Blob key must not start with forward slash (/).');
+		}
+		if (new TextEncoder().encode(key).length > 600) {
+			throw new Error(
+				'Blob key must be a sequence of Unicode characters whose UTF-8 encoding is at most 600 bytes long.',
+			);
+		}
+	}
+	static validateDeployID(deployID) {
+		if (!/^\w{1,24}$/.test(deployID)) {
+			throw new Error(`'${deployID}' is not a valid Netlify deploy ID.`);
+		}
+	}
+	static validateStoreName(name) {
+		if (name.includes('/') || name.includes('%2F')) {
+			throw new Error('Store name must not contain forward slashes (/).');
+		}
+		if (new TextEncoder().encode(name).length > 64) {
+			throw new Error(
+				'Store name must be a sequence of Unicode characters whose UTF-8 encoding is at most 64 bytes long.',
+			);
+		}
+	}
+	getListIterator(options) {
+		const { client, name: storeName } = this;
+		const parameters = {};
+		if (options?.prefix) {
+			parameters.prefix = options.prefix;
+		}
+		if (options?.directories) {
+			parameters.directories = 'true';
+		}
+		return {
+			[Symbol.asyncIterator]() {
+				let currentCursor = null;
+				let done = false;
+				return {
+					async next() {
+						if (done) {
+							return { done: true, value: void 0 };
+						}
+						const nextParameters = { ...parameters };
+						if (currentCursor !== null) {
+							nextParameters.cursor = currentCursor;
+						}
+						const res = await client.makeRequest({
+							method: 'get' /* GET */,
+							parameters: nextParameters,
+							storeName,
+						});
+						let blobs = [];
+						let directories = [];
+						if (![200, 204, 404].includes(res.status)) {
+							throw new BlobsInternalError(res);
+						}
+						if (res.status === 404) {
+							done = true;
+						} else {
+							const page = await res.json();
+							if (page.next_cursor) {
+								currentCursor = page.next_cursor;
+							} else {
+								done = true;
+							}
+							blobs = (page.blobs ?? []).map(_Store.formatListResultBlob).filter(Boolean);
+							directories = page.directories ?? [];
+						}
+						return {
+							done: false,
+							value: {
+								blobs,
+								directories,
+							},
+						};
+					},
+				};
+			},
+		};
+	}
 };
 
 // src/store_factory.ts
 var getDeployStore = (input = {}) => {
-  const context = getEnvironmentContext();
-  const options = typeof input === "string" ? { name: input } : input;
-  const deployID = options.deployID ?? context.deployID;
-  if (!deployID) {
-    throw new MissingBlobsEnvironmentError(["deployID"]);
-  }
-  const clientOptions = getClientOptions(options, context);
-  if (!clientOptions.region) {
-    if (clientOptions.edgeURL || clientOptions.uncachedEdgeURL) {
-      if (!context.primaryRegion) {
-        throw new Error(
-          "When accessing a deploy store, the Netlify Blobs client needs to be configured with a region, and one was not found in the environment. To manually set the region, set the `region` property in the `getDeployStore` options. If you are using the Netlify CLI, you may have an outdated version; run `npm install -g netlify-cli@latest` to update and try again."
-        );
-      }
-      clientOptions.region = context.primaryRegion;
-    } else {
-      clientOptions.region = REGION_AUTO;
-    }
-  }
-  const client = new Client(clientOptions);
-  return new Store({ client, deployID, name: options.name });
+	const context = getEnvironmentContext();
+	const options = typeof input === 'string' ? { name: input } : input;
+	const deployID = options.deployID ?? context.deployID;
+	if (!deployID) {
+		throw new MissingBlobsEnvironmentError(['deployID']);
+	}
+	const clientOptions = getClientOptions(options, context);
+	if (!clientOptions.region) {
+		if (clientOptions.edgeURL || clientOptions.uncachedEdgeURL) {
+			if (!context.primaryRegion) {
+				throw new Error(
+					'When accessing a deploy store, the Netlify Blobs client needs to be configured with a region, and one was not found in the environment. To manually set the region, set the `region` property in the `getDeployStore` options. If you are using the Netlify CLI, you may have an outdated version; run `npm install -g netlify-cli@latest` to update and try again.',
+				);
+			}
+			clientOptions.region = context.primaryRegion;
+		} else {
+			clientOptions.region = REGION_AUTO;
+		}
+	}
+	const client = new Client(clientOptions);
+	return new Store({ client, deployID, name: options.name });
 };
 var getStore = (input) => {
-  if (typeof input === "string") {
-    const clientOptions = getClientOptions({});
-    const client = new Client(clientOptions);
-    return new Store({ client, name: input });
-  }
-  if (typeof input?.name === "string" && typeof input?.siteID === "string" && typeof input?.token === "string") {
-    const { name, siteID, token } = input;
-    const clientOptions = getClientOptions(input, { siteID, token });
-    if (!name || !siteID || !token) {
-      throw new MissingBlobsEnvironmentError(["name", "siteID", "token"]);
-    }
-    const client = new Client(clientOptions);
-    return new Store({ client, name });
-  }
-  if (typeof input?.name === "string") {
-    const { name } = input;
-    const clientOptions = getClientOptions(input);
-    if (!name) {
-      throw new MissingBlobsEnvironmentError(["name"]);
-    }
-    const client = new Client(clientOptions);
-    return new Store({ client, name });
-  }
-  if (typeof input?.deployID === "string") {
-    const clientOptions = getClientOptions(input);
-    const { deployID } = input;
-    if (!deployID) {
-      throw new MissingBlobsEnvironmentError(["deployID"]);
-    }
-    const client = new Client(clientOptions);
-    return new Store({ client, deployID });
-  }
-  throw new Error(
-    "The `getStore` method requires the name of the store as a string or as the `name` property of an options object"
-  );
+	if (typeof input === 'string') {
+		const clientOptions = getClientOptions({});
+		const client = new Client(clientOptions);
+		return new Store({ client, name: input });
+	}
+	if (
+		typeof input?.name === 'string' &&
+		typeof input?.siteID === 'string' &&
+		typeof input?.token === 'string'
+	) {
+		const { name, siteID, token } = input;
+		const clientOptions = getClientOptions(input, { siteID, token });
+		if (!name || !siteID || !token) {
+			throw new MissingBlobsEnvironmentError(['name', 'siteID', 'token']);
+		}
+		const client = new Client(clientOptions);
+		return new Store({ client, name });
+	}
+	if (typeof input?.name === 'string') {
+		const { name } = input;
+		const clientOptions = getClientOptions(input);
+		if (!name) {
+			throw new MissingBlobsEnvironmentError(['name']);
+		}
+		const client = new Client(clientOptions);
+		return new Store({ client, name });
+	}
+	if (typeof input?.deployID === 'string') {
+		const clientOptions = getClientOptions(input);
+		const { deployID } = input;
+		if (!deployID) {
+			throw new MissingBlobsEnvironmentError(['deployID']);
+		}
+		const client = new Client(clientOptions);
+		return new Store({ client, deployID });
+	}
+	throw new Error(
+		'The `getStore` method requires the name of the store as a string or as the `name` property of an options object',
+	);
 };
 
 // src/store_list.ts
 function listStores(options = {}) {
-  const context = getEnvironmentContext();
-  const clientOptions = getClientOptions(options, context);
-  const client = new Client(clientOptions);
-  const iterator = getListIterator(client, SITE_STORE_PREFIX);
-  if (options.paginate) {
-    return iterator;
-  }
-  return collectIterator(iterator).then((results) => ({ stores: results.flatMap((page) => page.stores) }));
+	const context = getEnvironmentContext();
+	const clientOptions = getClientOptions(options, context);
+	const client = new Client(clientOptions);
+	const iterator = getListIterator(client, SITE_STORE_PREFIX);
+	if (options.paginate) {
+		return iterator;
+	}
+	return collectIterator(iterator).then((results) => ({
+		stores: results.flatMap((page) => page.stores),
+	}));
 }
-var formatListStoreResponse = (stores) => stores.filter((store) => !store.startsWith(DEPLOY_STORE_PREFIX)).map((store) => store.startsWith(SITE_STORE_PREFIX) ? store.slice(SITE_STORE_PREFIX.length) : store);
+var formatListStoreResponse = (stores) =>
+	stores
+		.filter((store) => !store.startsWith(DEPLOY_STORE_PREFIX))
+		.map((store) =>
+			store.startsWith(SITE_STORE_PREFIX) ? store.slice(SITE_STORE_PREFIX.length) : store,
+		);
 var getListIterator = (client, prefix) => {
-  const parameters = {
-    prefix
-  };
-  return {
-    [Symbol.asyncIterator]() {
-      let currentCursor = null;
-      let done = false;
-      return {
-        async next() {
-          if (done) {
-            return { done: true, value: void 0 };
-          }
-          const nextParameters = { ...parameters };
-          if (currentCursor !== null) {
-            nextParameters.cursor = currentCursor;
-          }
-          const res = await client.makeRequest({
-            method: "get" /* GET */,
-            parameters: nextParameters
-          });
-          if (res.status === 404) {
-            return { done: true, value: void 0 };
-          }
-          const page = await res.json();
-          if (page.next_cursor) {
-            currentCursor = page.next_cursor;
-          } else {
-            done = true;
-          }
-          return {
-            done: false,
-            value: {
-              ...page,
-              stores: formatListStoreResponse(page.stores)
-            }
-          };
-        }
-      };
-    }
-  };
-};
-export {
-  connectLambda,
-  getDeployStore,
-  getStore,
-  listStores,
-  setEnvironmentContext
+	const parameters = {
+		prefix,
+	};
+	return {
+		[Symbol.asyncIterator]() {
+			let currentCursor = null;
+			let done = false;
+			return {
+				async next() {
+					if (done) {
+						return { done: true, value: void 0 };
+					}
+					const nextParameters = { ...parameters };
+					if (currentCursor !== null) {
+						nextParameters.cursor = currentCursor;
+					}
+					const res = await client.makeRequest({
+						method: 'get' /* GET */,
+						parameters: nextParameters,
+					});
+					if (res.status === 404) {
+						return { done: true, value: void 0 };
+					}
+					const page = await res.json();
+					if (page.next_cursor) {
+						currentCursor = page.next_cursor;
+					} else {
+						done = true;
+					}
+					return {
+						done: false,
+						value: {
+							...page,
+							stores: formatListStoreResponse(page.stores),
+						},
+					};
+				},
+			};
+		},
+	};
 };
+export { connectLambda, getDeployStore, getStore, listStores, setEnvironmentContext };
diff --git a/dist/server.js b/dist/server.js
index 74ee475f0e81d7705c1664471f361f17596af78f..48a31a38f5be544ea7ee8c6df7a7e805923b2137 100644
--- a/dist/server.js
+++ b/dist/server.js
@@ -1,403 +1,409 @@
 import {
-  METADATA_HEADER_INTERNAL,
-  SIGNED_URL_ACCEPT_HEADER,
-  decodeMetadata,
-  decodeName,
-  encodeMetadata,
-  encodeName,
-  isNodeError
-} from "./chunk-HN33TXZT.js";
+	METADATA_HEADER_INTERNAL,
+	SIGNED_URL_ACCEPT_HEADER,
+	decodeMetadata,
+	decodeName,
+	encodeMetadata,
+	encodeName,
+	isNodeError,
+} from './chunk-HN33TXZT.js';
 
 // src/server.ts
-import { createHmac } from "crypto";
-import { createReadStream, promises as fs } from "fs";
-import { tmpdir } from "os";
-import { dirname, join, relative, resolve, sep } from "path";
-import { HTTPServer } from "@netlify/dev-utils";
+import { createHmac } from 'crypto';
+import { createReadStream, promises as fs } from 'fs';
+import { tmpdir } from 'os';
+import { dirname, join, relative, resolve, sep } from 'path';
+import { HTTPServer } from '@netlify/dev-utils';
 var API_URL_PATH = /\/api\/v1\/blobs\/(?<site_id>[^/]+)\/(?<store_name>[^/]+)\/?(?<key>[^?]*)/;
 var LEGACY_API_URL_PATH = /\/api\/v1\/sites\/(?<site_id>[^/]+)\/blobs\/?(?<key>[^?]*)/;
-var LEGACY_DEFAULT_STORE = "production";
-var REGION_PREFIX = "region:";
+var LEGACY_DEFAULT_STORE = 'production';
+var REGION_PREFIX = 'region:';
 var Operation = /* @__PURE__ */ ((Operation2) => {
-  Operation2["DELETE"] = "delete";
-  Operation2["GET"] = "get";
-  Operation2["GET_METADATA"] = "getMetadata";
-  Operation2["LIST"] = "list";
-  Operation2["SET"] = "set";
-  return Operation2;
+	Operation2['DELETE'] = 'delete';
+	Operation2['GET'] = 'get';
+	Operation2['GET_METADATA'] = 'getMetadata';
+	Operation2['LIST'] = 'list';
+	Operation2['SET'] = 'set';
+	return Operation2;
 })(Operation || {});
 var BlobsServer = class _BlobsServer {
-  constructor({ debug, directory, logger, onRequest, port, token }) {
-    this.address = "";
-    this.port = port;
-    this.debug = debug === true;
-    this.directory = directory;
-    this.logger = logger ?? console.log;
-    this.onRequest = onRequest;
-    this.token = token;
-    this.tokenHash = createHmac("sha256", Math.random.toString()).update(token ?? Math.random.toString()).digest("hex");
-  }
-  dispatchOnRequestEvent(type, input) {
-    if (!this.onRequest) {
-      return;
-    }
-    const url = new URL(input);
-    this.onRequest({ type, url: url.pathname + url.search });
-  }
-  async delete(req) {
-    const apiMatch = this.parseAPIRequest(req);
-    if (apiMatch?.useSignedURL) {
-      return Response.json({ url: apiMatch.url.toString() });
-    }
-    const url = new URL(apiMatch?.url ?? req.url ?? "", this.address);
-    const { dataPath, key, metadataPath } = this.getLocalPaths(url);
-    if (!dataPath || !key) {
-      return new Response(null, { status: 400 });
-    }
-    try {
-      await fs.rm(metadataPath, { force: true, recursive: true });
-    } catch {
-    }
-    try {
-      await fs.rm(dataPath, { force: true, recursive: true });
-    } catch (error) {
-      if (!isNodeError(error) || error.code !== "ENOENT") {
-        return new Response(null, { status: 500 });
-      }
-    }
-    return new Response(null, { status: 204 });
-  }
-  async get(req) {
-    const apiMatch = this.parseAPIRequest(req);
-    const url = apiMatch?.url ?? new URL(req.url ?? "", this.address);
-    if (apiMatch?.key && apiMatch?.useSignedURL) {
-      return Response.json({ url: apiMatch.url.toString() });
-    }
-    const { dataPath, key, metadataPath, rootPath } = this.getLocalPaths(apiMatch?.url ?? url);
-    if (!rootPath) {
-      return new Response(null, { status: 400 });
-    }
-    if (!dataPath || !metadataPath) {
-      return this.listStores(rootPath, url.searchParams.get("prefix") ?? "");
-    }
-    if (!key) {
-      return this.listBlobs({ dataPath, metadataPath, rootPath, req, url });
-    }
-    this.dispatchOnRequestEvent("get" /* GET */, url);
-    const headers = {};
-    try {
-      const rawData = await fs.readFile(metadataPath, "utf8");
-      const metadata = JSON.parse(rawData);
-      const encodedMetadata = encodeMetadata(metadata);
-      if (encodedMetadata) {
-        headers[METADATA_HEADER_INTERNAL] = encodedMetadata;
-      }
-    } catch (error) {
-      if (!isNodeError(error) || error.code !== "ENOENT") {
-        this.logDebug("Could not read metadata file:", error);
-      }
-    }
-    try {
-      const fileStream = createReadStream(dataPath);
-      const chunks = [];
-      for await (const chunk of fileStream) {
-        chunks.push(Buffer.from(chunk));
-      }
-      const buffer = Buffer.concat(chunks);
-      return new Response(buffer, { headers });
-    } catch (error) {
-      if (isNodeError(error) && (error.code === "EISDIR" || error.code === "ENOENT")) {
-        return new Response(null, { status: 404 });
-      }
-      this.logDebug("Error when reading data:", error);
-      return new Response(null, { status: 500 });
-    }
-  }
-  async head(req) {
-    const url = this.parseAPIRequest(req)?.url ?? new URL(req.url ?? "", this.address);
-    const { dataPath, key, metadataPath } = this.getLocalPaths(url);
-    if (!dataPath || !metadataPath || !key) {
-      return new Response(null, { status: 400 });
-    }
-    try {
-      const rawData = await fs.readFile(metadataPath, "utf8");
-      const metadata = JSON.parse(rawData);
-      const encodedMetadata = encodeMetadata(metadata);
-      return new Response(null, {
-        headers: {
-          [METADATA_HEADER_INTERNAL]: encodedMetadata ?? ""
-        }
-      });
-    } catch (error) {
-      if (isNodeError(error) && (error.code === "ENOENT" || error.code === "ISDIR")) {
-        return new Response(null, { status: 404 });
-      }
-      this.logDebug("Could not read metadata file:", error);
-      return new Response(null, { status: 500 });
-    }
-  }
-  async listBlobs(options) {
-    const { dataPath, rootPath, url } = options;
-    const directories = url.searchParams.get("directories") === "true";
-    const prefix = url.searchParams.get("prefix") ?? "";
-    const result = {
-      blobs: [],
-      directories: []
-    };
-    this.dispatchOnRequestEvent("list" /* LIST */, url);
-    try {
-      await _BlobsServer.walk({ directories, path: dataPath, prefix, rootPath, result });
-    } catch (error) {
-      if (!isNodeError(error) || error.code !== "ENOENT") {
-        this.logDebug("Could not perform list:", error);
-        return new Response(null, { status: 500 });
-      }
-    }
-    return Response.json(result);
-  }
-  async listStores(rootPath, prefix) {
-    try {
-      const allStores = await fs.readdir(rootPath);
-      const filteredStores = allStores.map(decodeName).filter((store) => store.startsWith(prefix));
-      return Response.json({ stores: filteredStores });
-    } catch (error) {
-      this.logDebug("Could not list stores:", error);
-      return new Response(null, { status: 500 });
-    }
-  }
-  logDebug(...message) {
-    if (!this.debug) {
-      return;
-    }
-    this.logger("[Netlify Blobs server]", ...message);
-  }
-  async put(req) {
-    const apiMatch = this.parseAPIRequest(req);
-    if (apiMatch) {
-      return Response.json({ url: apiMatch.url.toString() });
-    }
-    const url = new URL(req.url ?? "", this.address);
-    const { dataPath, key, metadataPath } = this.getLocalPaths(url);
-    if (!dataPath || !key || !metadataPath) {
-      return new Response(null, { status: 400 });
-    }
-    const ifMatch = req.headers.get("if-match");
-    const ifNoneMatch = req.headers.get("if-none-match");
-    try {
-      let fileExists = false;
-      try {
-        await fs.access(dataPath);
-        fileExists = true;
-      } catch {
-      }
-      const currentEtag = fileExists ? await _BlobsServer.generateETag(dataPath) : void 0;
-      if (ifNoneMatch === "*" && fileExists) {
-        return new Response(null, { status: 412 });
-      }
-      if (ifMatch && (!fileExists || ifMatch !== currentEtag)) {
-        return new Response(null, { status: 412 });
-      }
-      const metadataHeader = req.headers.get(METADATA_HEADER_INTERNAL);
-      const metadata = decodeMetadata(metadataHeader);
-      const tempPath = join(tmpdir(), Math.random().toString());
-      const body = await req.arrayBuffer();
-      await fs.writeFile(tempPath, Buffer.from(body));
-      await fs.mkdir(dirname(dataPath), { recursive: true });
-      await fs.rename(tempPath, dataPath);
-      if (metadata) {
-        await fs.mkdir(dirname(metadataPath), { recursive: true });
-        await fs.writeFile(metadataPath, JSON.stringify(metadata));
-      }
-      const newEtag = await _BlobsServer.generateETag(dataPath);
-      return new Response(null, {
-        status: 200,
-        headers: {
-          etag: newEtag
-        }
-      });
-    } catch (error) {
-      if (isNodeError(error)) {
-        this.logDebug("Error when writing data:", error);
-      }
-      return new Response(null, { status: 500 });
-    }
-  }
-  /**
-   * Parses the URL and returns the filesystem paths where entries and metadata
-   * should be stored.
-   */
-  getLocalPaths(url) {
-    if (!url) {
-      return {};
-    }
-    let parts = url.pathname.split("/").slice(1);
-    if (parts[0].startsWith(REGION_PREFIX)) {
-      parts = parts.slice(1);
-    }
-    const [siteID, rawStoreName, ...rawKey] = parts;
-    if (!siteID) {
-      return {};
-    }
-    const rootPath = resolve(this.directory, "entries", siteID);
-    if (!rawStoreName) {
-      return { rootPath };
-    }
-    const key = rawKey.map(encodeName);
-    const storeName = encodeName(rawStoreName);
-    const storePath = resolve(rootPath, storeName);
-    const dataPath = resolve(storePath, ...key);
-    const metadataPath = resolve(this.directory, "metadata", siteID, storeName, ...key);
-    return { dataPath, key: key.join("/"), metadataPath, rootPath: storePath };
-  }
-  /**
-   * Helper method to generate an ETag for a file based on its path and last modified time.
-   */
-  static async generateETag(filePath) {
-    try {
-      const stats = await fs.stat(filePath);
-      const hash = createHmac("sha256", stats.mtime.toISOString()).update(filePath).digest("hex");
-      return `"${hash}"`;
-    } catch {
-      return "";
-    }
-  }
-  async handleRequest(req) {
-    if (!req.url || !this.validateAccess(req)) {
-      return new Response(null, { status: 403 });
-    }
-    switch (req.method?.toLowerCase()) {
-      case "delete" /* DELETE */: {
-        this.dispatchOnRequestEvent("delete" /* DELETE */, req.url);
-        return this.delete(req);
-      }
-      case "get" /* GET */: {
-        return this.get(req);
-      }
-      case "put" /* PUT */: {
-        this.dispatchOnRequestEvent("set" /* SET */, req.url);
-        return this.put(req);
-      }
-      case "head" /* HEAD */: {
-        this.dispatchOnRequestEvent("getMetadata" /* GET_METADATA */, req.url);
-        return this.head(req);
-      }
-      default:
-        return new Response(null, { status: 405 });
-    }
-  }
-  /**
-   * Tries to parse a URL as being an API request and returns the different
-   * components, such as the store name, site ID, key, and signed URL.
-   */
-  parseAPIRequest(req) {
-    if (!req.url) {
-      return null;
-    }
-    const apiURLMatch = API_URL_PATH.exec(req.url);
-    if (apiURLMatch) {
-      const key = apiURLMatch.groups?.key;
-      const siteID = apiURLMatch.groups?.site_id;
-      const storeName = apiURLMatch.groups?.store_name;
-      const urlPath = [siteID, storeName, key].filter(Boolean);
-      const url = new URL(`/${urlPath.join("/")}?signature=${this.tokenHash}`, this.address);
-      return {
-        key,
-        siteID,
-        storeName,
-        url,
-        useSignedURL: req.headers.get("accept") === SIGNED_URL_ACCEPT_HEADER
-      };
-    }
-    const legacyAPIURLMatch = LEGACY_API_URL_PATH.exec(req.url);
-    if (legacyAPIURLMatch) {
-      const fullURL = new URL(req.url, this.address);
-      const storeName = fullURL.searchParams.get("context") ?? LEGACY_DEFAULT_STORE;
-      const key = legacyAPIURLMatch.groups?.key;
-      const siteID = legacyAPIURLMatch.groups?.site_id;
-      const urlPath = [siteID, storeName, key].filter(Boolean);
-      const url = new URL(`/${urlPath.join("/")}?signature=${this.tokenHash}`, this.address);
-      return {
-        key,
-        siteID,
-        storeName,
-        url,
-        useSignedURL: true
-      };
-    }
-    return null;
-  }
-  validateAccess(req) {
-    if (!this.token) {
-      return true;
-    }
-    const authorization = req.headers.get("authorization") || "";
-    if (authorization.toLowerCase().startsWith("bearer ") && authorization.slice("bearer ".length) === this.token) {
-      return true;
-    }
-    if (!req.url) {
-      return false;
-    }
-    const url = new URL(req.url, this.address);
-    const signature = url.searchParams.get("signature");
-    if (signature === this.tokenHash) {
-      return true;
-    }
-    return false;
-  }
-  /**
-   * Traverses a path and collects both blobs and directories into a `result`
-   * object, taking into account the `directories` and `prefix` parameters.
-   */
-  static async walk(options) {
-    const { directories, path, prefix, result, rootPath } = options;
-    const entries = await fs.readdir(path);
-    for (const entry of entries) {
-      const entryPath = join(path, entry);
-      const stat = await fs.stat(entryPath);
-      let key = relative(rootPath, entryPath);
-      if (sep !== "/") {
-        key = key.split(sep).join("/");
-      }
-      const mask = key.slice(0, prefix.length);
-      const isMatch = prefix.startsWith(mask);
-      if (!isMatch) {
-        continue;
-      }
-      if (!stat.isDirectory()) {
-        const etag = await this.generateETag(entryPath);
-        result.blobs?.push({
-          etag,
-          key,
-          last_modified: stat.mtime.toISOString(),
-          size: stat.size
-        });
-        continue;
-      }
-      if (directories && key.startsWith(prefix)) {
-        result.directories?.push(key);
-        continue;
-      }
-      await _BlobsServer.walk({ directories, path: entryPath, prefix, rootPath, result });
-    }
-  }
-  async start() {
-    await fs.mkdir(this.directory, { recursive: true });
-    const server = new HTTPServer((req) => this.handleRequest(req));
-    const address = await server.start(this.port ?? 0);
-    const port = Number.parseInt(new URL(address).port);
-    this.address = address;
-    this.server = server;
-    return {
-      address,
-      family: "ipv4",
-      port
-    };
-  }
-  async stop() {
-    return this.server?.stop();
-  }
-};
-export {
-  BlobsServer,
-  Operation
+	constructor({ debug, directory, logger, onRequest, port, token }) {
+		this.address = '';
+		this.port = port;
+		this.debug = debug === true;
+		this.directory = directory;
+		this.logger = logger ?? console.log;
+		this.onRequest = onRequest;
+		this.token = token;
+		this.tokenHash = createHmac('sha256', Math.random.toString())
+			.update(token ?? Math.random.toString())
+			.digest('hex');
+	}
+	dispatchOnRequestEvent(type, input) {
+		if (!this.onRequest) {
+			return;
+		}
+		const url = new URL(input);
+		this.onRequest({ type, url: url.pathname + url.search });
+	}
+	async delete(req) {
+		const apiMatch = this.parseAPIRequest(req);
+		if (apiMatch?.useSignedURL) {
+			return Response.json({ url: apiMatch.url.toString() });
+		}
+		const url = new URL(apiMatch?.url ?? req.url ?? '', this.address);
+		const { dataPath, key, metadataPath } = this.getLocalPaths(url);
+		if (!dataPath || !key) {
+			return new Response(null, { status: 400 });
+		}
+		try {
+			await fs.rm(metadataPath, { force: true, recursive: true });
+		} catch {}
+		try {
+			await fs.rm(dataPath, { force: true, recursive: true });
+		} catch (error) {
+			if (!isNodeError(error) || error.code !== 'ENOENT') {
+				return new Response(null, { status: 500 });
+			}
+		}
+		return new Response(null, { status: 204 });
+	}
+	async get(req) {
+		const apiMatch = this.parseAPIRequest(req);
+		const url = apiMatch?.url ?? new URL(req.url ?? '', this.address);
+		if (apiMatch?.key && apiMatch?.useSignedURL) {
+			return Response.json({ url: apiMatch.url.toString() });
+		}
+		const { dataPath, key, metadataPath, rootPath } = this.getLocalPaths(apiMatch?.url ?? url);
+		if (!rootPath) {
+			return new Response(null, { status: 400 });
+		}
+		if (!dataPath || !metadataPath) {
+			return this.listStores(rootPath, url.searchParams.get('prefix') ?? '');
+		}
+		if (!key) {
+			return this.listBlobs({ dataPath, metadataPath, rootPath, req, url });
+		}
+		this.dispatchOnRequestEvent('get' /* GET */, url);
+		const headers = {};
+		try {
+			const rawData = await fs.readFile(metadataPath, 'utf8');
+			const metadata = JSON.parse(rawData);
+			const encodedMetadata = encodeMetadata(metadata);
+			if (encodedMetadata) {
+				headers[METADATA_HEADER_INTERNAL] = encodedMetadata;
+			}
+		} catch (error) {
+			if (!isNodeError(error) || error.code !== 'ENOENT') {
+				this.logDebug('Could not read metadata file:', error);
+			}
+		}
+		try {
+			const fileStream = createReadStream(dataPath);
+			const chunks = [];
+			for await (const chunk of fileStream) {
+				chunks.push(Buffer.from(chunk));
+			}
+			const buffer = Buffer.concat(chunks);
+			return new Response(buffer, { headers });
+		} catch (error) {
+			if (isNodeError(error) && (error.code === 'EISDIR' || error.code === 'ENOENT')) {
+				return new Response(null, { status: 404 });
+			}
+			this.logDebug('Error when reading data:', error);
+			return new Response(null, { status: 500 });
+		}
+	}
+	async head(req) {
+		const url = this.parseAPIRequest(req)?.url ?? new URL(req.url ?? '', this.address);
+		const { dataPath, key, metadataPath } = this.getLocalPaths(url);
+		if (!dataPath || !metadataPath || !key) {
+			return new Response(null, { status: 400 });
+		}
+		try {
+			const rawData = await fs.readFile(metadataPath, 'utf8');
+			const metadata = JSON.parse(rawData);
+			const encodedMetadata = encodeMetadata(metadata);
+			return new Response(null, {
+				headers: {
+					[METADATA_HEADER_INTERNAL]: encodedMetadata ?? '',
+				},
+			});
+		} catch (error) {
+			if (isNodeError(error) && (error.code === 'ENOENT' || error.code === 'ISDIR')) {
+				return new Response(null, { status: 404 });
+			}
+			this.logDebug('Could not read metadata file:', error);
+			return new Response(null, { status: 500 });
+		}
+	}
+	async listBlobs(options) {
+		const { dataPath, rootPath, url } = options;
+		const directories = url.searchParams.get('directories') === 'true';
+		const prefix = url.searchParams.get('prefix') ?? '';
+		const result = {
+			blobs: [],
+			directories: [],
+		};
+		this.dispatchOnRequestEvent('list' /* LIST */, url);
+		try {
+			await _BlobsServer.walk({ directories, path: dataPath, prefix, rootPath, result });
+		} catch (error) {
+			if (!isNodeError(error) || error.code !== 'ENOENT') {
+				this.logDebug('Could not perform list:', error);
+				return new Response(null, { status: 500 });
+			}
+		}
+		return Response.json(result);
+	}
+	async listStores(rootPath, prefix) {
+		try {
+			const allStores = await fs.readdir(rootPath);
+			const filteredStores = allStores.map(decodeName).filter((store) => store.startsWith(prefix));
+			return Response.json({ stores: filteredStores });
+		} catch (error) {
+			this.logDebug('Could not list stores:', error);
+			return new Response(null, { status: 500 });
+		}
+	}
+	logDebug(...message) {
+		if (!this.debug) {
+			return;
+		}
+		this.logger('[Netlify Blobs server]', ...message);
+	}
+	async put(req) {
+		const apiMatch = this.parseAPIRequest(req);
+		if (apiMatch) {
+			return Response.json({ url: apiMatch.url.toString() });
+		}
+		const url = new URL(req.url ?? '', this.address);
+		const { dataPath, key, metadataPath } = this.getLocalPaths(url);
+		if (!dataPath || !key || !metadataPath) {
+			return new Response(null, { status: 400 });
+		}
+		const ifMatch = req.headers.get('if-match');
+		const ifNoneMatch = req.headers.get('if-none-match');
+		try {
+			let fileExists = false;
+			try {
+				await fs.access(dataPath);
+				fileExists = true;
+			} catch {}
+			const currentEtag = fileExists ? await _BlobsServer.generateETag(dataPath) : void 0;
+			if (ifNoneMatch === '*' && fileExists) {
+				return new Response(null, { status: 412 });
+			}
+			if (ifMatch && (!fileExists || ifMatch !== currentEtag)) {
+				return new Response(null, { status: 412 });
+			}
+			const metadataHeader = req.headers.get(METADATA_HEADER_INTERNAL);
+			const metadata = decodeMetadata(metadataHeader);
+			const tempPath = join(tmpdir(), Math.random().toString());
+			const body = await req.arrayBuffer();
+			await fs.writeFile(tempPath, Buffer.from(body));
+			await fs.mkdir(dirname(dataPath), { recursive: true });
+			await fs.rename(tempPath, dataPath);
+			if (metadata) {
+				await fs.mkdir(dirname(metadataPath), { recursive: true });
+				await fs.writeFile(metadataPath, JSON.stringify(metadata));
+			}
+			const newEtag = await _BlobsServer.generateETag(dataPath);
+			return new Response(null, {
+				status: 200,
+				headers: {
+					etag: newEtag,
+				},
+			});
+		} catch (error) {
+			console.error('gonna 500 btw');
+			console.error(error);
+			if (isNodeError(error)) {
+				this.logDebug('Error when writing data:', error);
+			}
+			return new Response(null, { status: 500 });
+		}
+	}
+	/**
+	 * Parses the URL and returns the filesystem paths where entries and metadata
+	 * should be stored.
+	 */
+	getLocalPaths(url) {
+		if (!url) {
+			return {};
+		}
+		let parts = url.pathname.split('/').slice(1);
+		if (parts[0].startsWith(REGION_PREFIX)) {
+			parts = parts.slice(1);
+		}
+		const [siteID, rawStoreName, ...rawKey] = parts;
+		if (!siteID) {
+			return {};
+		}
+		const rootPath = resolve(this.directory, 'entries', siteID);
+		if (!rawStoreName) {
+			return { rootPath };
+		}
+		const key = rawKey.map(encodeName);
+		const storeName = encodeName(rawStoreName);
+		const storePath = resolve(rootPath, storeName);
+		const dataPath = resolve(storePath, ...key);
+		const metadataPath = resolve(this.directory, 'metadata', siteID, storeName, ...key);
+		return { dataPath, key: key.join('/'), metadataPath, rootPath: storePath };
+	}
+	/**
+	 * Helper method to generate an ETag for a file based on its path and last modified time.
+	 */
+	static async generateETag(filePath) {
+		try {
+			const stats = await fs.stat(filePath);
+			const hash = createHmac('sha256', stats.mtime.toISOString()).update(filePath).digest('hex');
+			return `"${hash}"`;
+		} catch {
+			return '';
+		}
+	}
+	async handleRequest(req) {
+		if (!req.url || !this.validateAccess(req)) {
+			return new Response(null, { status: 403 });
+		}
+		switch (req.method?.toLowerCase()) {
+			case 'delete' /* DELETE */: {
+				this.dispatchOnRequestEvent('delete' /* DELETE */, req.url);
+				console.log('delete', req.url);
+				return this.delete(req);
+			}
+			case 'get' /* GET */: {
+				console.log('get', req.url);
+				return this.get(req);
+			}
+			case 'put' /* PUT */: {
+				console.log('put', req.url);
+				this.dispatchOnRequestEvent('set' /* SET */, req.url);
+				return this.put(req);
+			}
+			case 'head' /* HEAD */: {
+				console.log('head', req.url);
+				this.dispatchOnRequestEvent('getMetadata' /* GET_METADATA */, req.url);
+				return this.head(req);
+			}
+			default:
+				return new Response(null, { status: 405 });
+		}
+	}
+	/**
+	 * Tries to parse a URL as being an API request and returns the different
+	 * components, such as the store name, site ID, key, and signed URL.
+	 */
+	parseAPIRequest(req) {
+		if (!req.url) {
+			return null;
+		}
+		const apiURLMatch = API_URL_PATH.exec(req.url);
+		if (apiURLMatch) {
+			const key = apiURLMatch.groups?.key;
+			const siteID = apiURLMatch.groups?.site_id;
+			const storeName = apiURLMatch.groups?.store_name;
+			const urlPath = [siteID, storeName, key].filter(Boolean);
+			const url = new URL(`/${urlPath.join('/')}?signature=${this.tokenHash}`, this.address);
+			return {
+				key,
+				siteID,
+				storeName,
+				url,
+				useSignedURL: req.headers.get('accept') === SIGNED_URL_ACCEPT_HEADER,
+			};
+		}
+		const legacyAPIURLMatch = LEGACY_API_URL_PATH.exec(req.url);
+		if (legacyAPIURLMatch) {
+			const fullURL = new URL(req.url, this.address);
+			const storeName = fullURL.searchParams.get('context') ?? LEGACY_DEFAULT_STORE;
+			const key = legacyAPIURLMatch.groups?.key;
+			const siteID = legacyAPIURLMatch.groups?.site_id;
+			const urlPath = [siteID, storeName, key].filter(Boolean);
+			const url = new URL(`/${urlPath.join('/')}?signature=${this.tokenHash}`, this.address);
+			return {
+				key,
+				siteID,
+				storeName,
+				url,
+				useSignedURL: true,
+			};
+		}
+		return null;
+	}
+	validateAccess(req) {
+		if (!this.token) {
+			return true;
+		}
+		const authorization = req.headers.get('authorization') || '';
+		if (
+			authorization.toLowerCase().startsWith('bearer ') &&
+			authorization.slice('bearer '.length) === this.token
+		) {
+			return true;
+		}
+		if (!req.url) {
+			return false;
+		}
+		const url = new URL(req.url, this.address);
+		const signature = url.searchParams.get('signature');
+		if (signature === this.tokenHash) {
+			return true;
+		}
+		return false;
+	}
+	/**
+	 * Traverses a path and collects both blobs and directories into a `result`
+	 * object, taking into account the `directories` and `prefix` parameters.
+	 */
+	static async walk(options) {
+		const { directories, path, prefix, result, rootPath } = options;
+		const entries = await fs.readdir(path);
+		for (const entry of entries) {
+			const entryPath = join(path, entry);
+			const stat = await fs.stat(entryPath);
+			let key = relative(rootPath, entryPath);
+			if (sep !== '/') {
+				key = key.split(sep).join('/');
+			}
+			const mask = key.slice(0, prefix.length);
+			const isMatch = prefix.startsWith(mask);
+			if (!isMatch) {
+				continue;
+			}
+			if (!stat.isDirectory()) {
+				const etag = await this.generateETag(entryPath);
+				result.blobs?.push({
+					etag,
+					key,
+					last_modified: stat.mtime.toISOString(),
+					size: stat.size,
+				});
+				continue;
+			}
+			if (directories && key.startsWith(prefix)) {
+				result.directories?.push(key);
+				continue;
+			}
+			await _BlobsServer.walk({ directories, path: entryPath, prefix, rootPath, result });
+		}
+	}
+	async start() {
+		await fs.mkdir(this.directory, { recursive: true });
+		const server = new HTTPServer((req) => this.handleRequest(req));
+		const address = await server.start(this.port ?? 0);
+		const port = Number.parseInt(new URL(address).port);
+		this.address = address;
+		this.server = server;
+		return {
+			address,
+			family: 'ipv4',
+			port,
+		};
+	}
+	async stop() {
+		return this.server?.stop();
+	}
 };
+export { BlobsServer, Operation };
